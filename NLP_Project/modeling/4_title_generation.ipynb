{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title Generation\n",
    "BIG KINDS에서 다운로드 받은 뉴스 기사 중 100000개를 선정하여 사용한다.\n",
    "\n",
    "### 필요 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from konlpy.tag import Mecab\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Input, Bidirectional, LSTM, Dense, Concatenate\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>제목</th>\n",
       "      <th>본문</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>음악으로 교감하는 싱글맘과 반항아 아들  영화 '플로라 앤 썬'</td>\n",
       "      <td>아일랜드 더블린의 한 동네 클럽에서 열리는 아마추어 동네 음악 경연 대회. 이제 열...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>오뚜기와 해태 설립의 '나비효과' 김치볶음밥의 탄생[책마을]</td>\n",
       "      <td>프라이팬이 한국에 전해진 것은 일제강점기였지만 대중화된 것은 1970년대부터였다. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'수산물 소비' 식당 시장 희비에도  손님은 '불안불안'</td>\n",
       "      <td>지금 당장은 괜찮을 것 같아 먹긴 하지만 불안이 가시진 않는다. 나중이 걱정이죠.일...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>수원 국회의원, 7개 공통 공약 중 3년간 3개 이행 [경기 인천 국회의원 공약 점검 ]</td>\n",
       "      <td>사진 왼쪽부터 김승원, 백혜련, 김영진, 박광온, 김진표 국회의원. 의원실 제공  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>수원 미완 공약, 22대 국회로 넘어가나 [경기 인천 국회의원 공약 점검 ]</td>\n",
       "      <td>수원군공항 모습. 경기일보DB  수원특례시 국회의원들이 제시한 7대 공통 공약 중 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>죽 쒔던 퇴직연금 증시 반등에 화색</td>\n",
       "      <td>올해 2분기 원리금비보장 퇴직연금 손익률이 일제히 수익으로 전환했다. 두 자릿수 손...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>이수과천 복합터널 건설 본궤도 2030년 개통</td>\n",
       "      <td>동작대로의 상습 정체를 해결하기 위한 '이수과천 복합터널' 건설사업이 본궤도에 올랐...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>[속보] 민주당 40대 김포시의원 길가서 숨진 채 발견 부검 의뢰 예정</td>\n",
       "      <td>더불어민주당 소속 김포시의원이 길가에서 숨진 채 발견돼 경찰이 수사에 나섰다.20일...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>신세계그룹, CEO 40 교체 쇄신인사 이마트 유통 3사 한채양 원톱 체제로</td>\n",
       "      <td>신세계그룹이 변화와 쇄신을 키워드로 2024년 정기 임원인사를 단행했다. 이번 인사...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>조민 아버지, 차라리 나를 고문하라 격노...김형주 전 의원 그리 당당하게 얘기 하냐</td>\n",
       "      <td>약 30만 구독자를 보유한 유튜버로 활동하고 있는 조국 전 법무부 장관의 딸 조민씨...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     제목  \\\n",
       "0                   음악으로 교감하는 싱글맘과 반항아 아들  영화 '플로라 앤 썬'   \n",
       "1                     오뚜기와 해태 설립의 '나비효과' 김치볶음밥의 탄생[책마을]   \n",
       "2                       '수산물 소비' 식당 시장 희비에도  손님은 '불안불안'   \n",
       "3     수원 국회의원, 7개 공통 공약 중 3년간 3개 이행 [경기 인천 국회의원 공약 점검 ]   \n",
       "4            수원 미완 공약, 22대 국회로 넘어가나 [경기 인천 국회의원 공약 점검 ]   \n",
       "...                                                 ...   \n",
       "7995                                죽 쒔던 퇴직연금 증시 반등에 화색   \n",
       "7996                          이수과천 복합터널 건설 본궤도 2030년 개통   \n",
       "7997            [속보] 민주당 40대 김포시의원 길가서 숨진 채 발견 부검 의뢰 예정   \n",
       "7998         신세계그룹, CEO 40 교체 쇄신인사 이마트 유통 3사 한채양 원톱 체제로   \n",
       "7999    조민 아버지, 차라리 나를 고문하라 격노...김형주 전 의원 그리 당당하게 얘기 하냐   \n",
       "\n",
       "                                                     본문  \n",
       "0     아일랜드 더블린의 한 동네 클럽에서 열리는 아마추어 동네 음악 경연 대회. 이제 열...  \n",
       "1     프라이팬이 한국에 전해진 것은 일제강점기였지만 대중화된 것은 1970년대부터였다. ...  \n",
       "2     지금 당장은 괜찮을 것 같아 먹긴 하지만 불안이 가시진 않는다. 나중이 걱정이죠.일...  \n",
       "3     사진 왼쪽부터 김승원, 백혜련, 김영진, 박광온, 김진표 국회의원. 의원실 제공  ...  \n",
       "4     수원군공항 모습. 경기일보DB  수원특례시 국회의원들이 제시한 7대 공통 공약 중 ...  \n",
       "...                                                 ...  \n",
       "7995  올해 2분기 원리금비보장 퇴직연금 손익률이 일제히 수익으로 전환했다. 두 자릿수 손...  \n",
       "7996  동작대로의 상습 정체를 해결하기 위한 '이수과천 복합터널' 건설사업이 본궤도에 올랐...  \n",
       "7997  더불어민주당 소속 김포시의원이 길가에서 숨진 채 발견돼 경찰이 수사에 나섰다.20일...  \n",
       "7998  신세계그룹이 변화와 쇄신을 키워드로 2024년 정기 임원인사를 단행했다. 이번 인사...  \n",
       "7999  약 30만 구독자를 보유한 유튜버로 활동하고 있는 조국 전 법무부 장관의 딸 조민씨...  \n",
       "\n",
       "[8000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CSV 파일 읽기\n",
    "df = pd.read_csv('Merged_NewsResults.csv')[:8000]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 간단한 데이터 전처리\n",
    "한글과 알파벳을 제외한 문자들을 제거한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['본문'] = df['본문'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣a-zA-Z ]\", \"\", regex=True)\n",
    "df['제목'] = df['제목'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣a-zA-Z ]\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>제목</th>\n",
       "      <th>본문</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>음악으로 교감하는 싱글맘과 반항아 아들  영화 플로라 앤 썬</td>\n",
       "      <td>아일랜드 더블린의 한 동네 클럽에서 열리는 아마추어 동네 음악 경연 대회 이제 열네...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>오뚜기와 해태 설립의 나비효과 김치볶음밥의 탄생책마을</td>\n",
       "      <td>프라이팬이 한국에 전해진 것은 일제강점기였지만 대중화된 것은 년대부터였다 오뚜기와 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>수산물 소비 식당 시장 희비에도  손님은 불안불안</td>\n",
       "      <td>지금 당장은 괜찮을 것 같아 먹긴 하지만 불안이 가시진 않는다 나중이 걱정이죠일본 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>수원 국회의원 개 공통 공약 중 년간 개 이행 경기 인천 국회의원 공약 점검</td>\n",
       "      <td>사진 왼쪽부터 김승원 백혜련 김영진 박광온 김진표 국회의원 의원실 제공  대 국회의...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>수원 미완 공약 대 국회로 넘어가나 경기 인천 국회의원 공약 점검</td>\n",
       "      <td>수원군공항 모습 경기일보DB  수원특례시 국회의원들이 제시한 대 공통 공약 중 대 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>죽 쒔던 퇴직연금 증시 반등에 화색</td>\n",
       "      <td>올해 분기 원리금비보장 퇴직연금 손익률이 일제히 수익으로 전환했다 두 자릿수 손실 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>이수과천 복합터널 건설 본궤도 년 개통</td>\n",
       "      <td>동작대로의 상습 정체를 해결하기 위한 이수과천 복합터널 건설사업이 본궤도에 올랐다 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>속보 민주당 대 김포시의원 길가서 숨진 채 발견 부검 의뢰 예정</td>\n",
       "      <td>더불어민주당 소속 김포시의원이 길가에서 숨진 채 발견돼 경찰이 수사에 나섰다일 경기...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>신세계그룹 CEO  교체 쇄신인사 이마트 유통 사 한채양 원톱 체제로</td>\n",
       "      <td>신세계그룹이 변화와 쇄신을 키워드로 년 정기 임원인사를 단행했다 이번 인사는 성과총...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>조민 아버지 차라리 나를 고문하라 격노김형주 전 의원 그리 당당하게 얘기 하냐</td>\n",
       "      <td>약 만 구독자를 보유한 유튜버로 활동하고 있는 조국 전 법무부 장관의 딸 조민씨가 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               제목  \\\n",
       "0               음악으로 교감하는 싱글맘과 반항아 아들  영화 플로라 앤 썬   \n",
       "1                   오뚜기와 해태 설립의 나비효과 김치볶음밥의 탄생책마을   \n",
       "2                     수산물 소비 식당 시장 희비에도  손님은 불안불안   \n",
       "3     수원 국회의원 개 공통 공약 중 년간 개 이행 경기 인천 국회의원 공약 점검    \n",
       "4           수원 미완 공약 대 국회로 넘어가나 경기 인천 국회의원 공약 점검    \n",
       "...                                           ...   \n",
       "7995                          죽 쒔던 퇴직연금 증시 반등에 화색   \n",
       "7996                        이수과천 복합터널 건설 본궤도 년 개통   \n",
       "7997          속보 민주당 대 김포시의원 길가서 숨진 채 발견 부검 의뢰 예정   \n",
       "7998       신세계그룹 CEO  교체 쇄신인사 이마트 유통 사 한채양 원톱 체제로   \n",
       "7999  조민 아버지 차라리 나를 고문하라 격노김형주 전 의원 그리 당당하게 얘기 하냐   \n",
       "\n",
       "                                                     본문  \n",
       "0     아일랜드 더블린의 한 동네 클럽에서 열리는 아마추어 동네 음악 경연 대회 이제 열네...  \n",
       "1     프라이팬이 한국에 전해진 것은 일제강점기였지만 대중화된 것은 년대부터였다 오뚜기와 ...  \n",
       "2     지금 당장은 괜찮을 것 같아 먹긴 하지만 불안이 가시진 않는다 나중이 걱정이죠일본 ...  \n",
       "3     사진 왼쪽부터 김승원 백혜련 김영진 박광온 김진표 국회의원 의원실 제공  대 국회의...  \n",
       "4     수원군공항 모습 경기일보DB  수원특례시 국회의원들이 제시한 대 공통 공약 중 대 ...  \n",
       "...                                                 ...  \n",
       "7995  올해 분기 원리금비보장 퇴직연금 손익률이 일제히 수익으로 전환했다 두 자릿수 손실 ...  \n",
       "7996  동작대로의 상습 정체를 해결하기 위한 이수과천 복합터널 건설사업이 본궤도에 올랐다 ...  \n",
       "7997  더불어민주당 소속 김포시의원이 길가에서 숨진 채 발견돼 경찰이 수사에 나섰다일 경기...  \n",
       "7998  신세계그룹이 변화와 쇄신을 키워드로 년 정기 임원인사를 단행했다 이번 인사는 성과총...  \n",
       "7999  약 만 구독자를 보유한 유튜버로 활동하고 있는 조국 전 법무부 장관의 딸 조민씨가 ...  \n",
       "\n",
       "[8000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Split\n",
    "Encoder용 데이터와 Decoder용 데이터를 분할한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터와 타겟 데이터 생성\n",
    "encoder_texts = df['제목'][:4000].astype(str).to_list()\n",
    "decoder_texts = df['제목'][4000:8000].astype(str).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 4000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoder_texts), len(decoder_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분리\n",
    "encoder_texts_train, encoder_texts_test, decoder_texts_train, decoder_texts_test = train_test_split(\n",
    "    encoder_texts, \n",
    "    decoder_texts, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab(r\"C:\\mecab\\mecab-ko-dic\")\n",
    "\n",
    "encoder_train_texts_tokenized = [mecab.morphs(item) for item in encoder_texts_train if item not in stopwords]\n",
    "encoder_test_texts_tokenized = [mecab.morphs(item) for item in encoder_texts_test if item not in stopwords]\n",
    "decoder_train_texts_tokenized = [mecab.morphs(item) for item in decoder_texts_train if item not in stopwords]\n",
    "decoder_test_texts_tokenized = [mecab.morphs(item) for item in decoder_texts_test if item not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_train_texts = []\n",
    "encoder_test_texts = []\n",
    "decoder_train_texts = []\n",
    "decoder_test_texts = []\n",
    "\n",
    "for row in encoder_train_texts_tokenized:\n",
    "    for col in row:\n",
    "        encoder_train_texts.append(col)\n",
    "        \n",
    "for row in encoder_test_texts_tokenized:\n",
    "    for col in row:\n",
    "        encoder_test_texts.append(col)\n",
    "        \n",
    "for row in decoder_train_texts_tokenized:\n",
    "    for col in row:\n",
    "        decoder_train_texts.append(col)\n",
    "        \n",
    "for row in decoder_test_texts_tokenized:\n",
    "    for col in row:\n",
    "        decoder_test_texts.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토큰화\n",
    "keras에서 제공하는 Tokenizer의 text_to_sequences로 토큰화한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화\n",
    "tokenizer_encoder = Tokenizer()\n",
    "tokenizer_encoder.fit_on_texts(encoder_texts_train)\n",
    "num_encoder_tokens = len(tokenizer_encoder.word_index) + 1\n",
    "\n",
    "tokenizer_decoder = Tokenizer()\n",
    "tokenizer_decoder.fit_on_texts(decoder_texts_train)\n",
    "num_decoder_tokens = len(tokenizer_decoder.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_sequences_train = tokenizer_encoder.texts_to_sequences(encoder_texts_train)\n",
    "encoder_sequences_test = tokenizer_encoder.texts_to_sequences(encoder_texts_test)\n",
    "\n",
    "decoder_sequences_train = tokenizer_decoder.texts_to_sequences(decoder_texts_train)\n",
    "decoder_sequences_test = tokenizer_decoder.texts_to_sequences(decoder_texts_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 패딩을 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_seq_length = max(len(seq) for seq in encoder_sequences_train)\n",
    "max_decoder_seq_length = max(len(seq) for seq in decoder_sequences_train)\n",
    "\n",
    "encoder_input_data_train = pad_sequences(encoder_sequences_train, maxlen=max_encoder_seq_length, padding='post')\n",
    "encoder_input_data_test = pad_sequences(encoder_sequences_test, maxlen=max_encoder_seq_length, padding='post')\n",
    "\n",
    "decoder_input_data_train = pad_sequences(decoder_sequences_train, maxlen=max_decoder_seq_length, padding='post')\n",
    "decoder_input_data_test = pad_sequences(decoder_sequences_test, maxlen=max_decoder_seq_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder ont-hot encoding\n",
    "decoder_output_data_train = np.zeros((len(decoder_sequences_train), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "decoder_output_data_test = np.zeros((len(decoder_sequences_test), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "\n",
    "for i, seqs in enumerate(decoder_sequences_train):\n",
    "    for j, seq in enumerate(seqs):\n",
    "        decoder_output_data_train[i, j, seq] = 1.\n",
    "\n",
    "for i, seqs in enumerate(decoder_sequences_test):\n",
    "    for j, seq in enumerate(seqs):\n",
    "        decoder_output_data_test[i, j, seq] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "latent_dim = 100  # 잠재 공간의 차원\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "encoder_embedding = Embedding(num_encoder_tokens, latent_dim, mask_zero=True)(encoder_inputs)\n",
    "encoder_bilstm = Bidirectional(LSTM(latent_dim, return_state=True))\n",
    "_, forward_h, forward_c, backward_h, backward_c = encoder_bilstm(encoder_embedding)\n",
    "state_h = Concatenate()([forward_h, backward_h])\n",
    "state_c = Concatenate()([forward_c, backward_c])\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "decoder_embedding = Embedding(num_decoder_tokens, latent_dim, mask_zero=True)(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim * 2, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "80/80 [==============================] - 10s 55ms/step - loss: 3.9090 - accuracy: 0.0122 - val_loss: 3.8718 - val_accuracy: 0.0072\n",
      "Epoch 2/15\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 3.6252 - accuracy: 0.0083 - val_loss: 3.6352 - val_accuracy: 0.0126\n",
      "Epoch 3/15\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 3.3672 - accuracy: 0.0117 - val_loss: 3.6369 - val_accuracy: 0.0131\n",
      "Epoch 4/15\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 3.1887 - accuracy: 0.0164 - val_loss: 3.7072 - val_accuracy: 0.0192\n",
      "Epoch 5/15\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 3.0127 - accuracy: 0.0235 - val_loss: 3.8512 - val_accuracy: 0.0253\n",
      "Epoch 6/15\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 2.8326 - accuracy: 0.0348 - val_loss: 3.8907 - val_accuracy: 0.0366\n",
      "Epoch 7/15\n",
      "80/80 [==============================] - 3s 36ms/step - loss: 2.6533 - accuracy: 0.0501 - val_loss: 3.9499 - val_accuracy: 0.0418\n",
      "Epoch 8/15\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 2.4810 - accuracy: 0.0662 - val_loss: 4.0184 - val_accuracy: 0.0470\n",
      "Epoch 9/15\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 2.3105 - accuracy: 0.0955 - val_loss: 4.0596 - val_accuracy: 0.0518\n",
      "Epoch 10/15\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 2.1444 - accuracy: 0.1285 - val_loss: 4.1284 - val_accuracy: 0.0581\n",
      "Epoch 11/15\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 1.9844 - accuracy: 0.1834 - val_loss: 4.1539 - val_accuracy: 0.0653\n",
      "Epoch 12/15\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 1.8278 - accuracy: 0.2531 - val_loss: 4.1743 - val_accuracy: 0.0738\n",
      "Epoch 13/15\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 1.6746 - accuracy: 0.3367 - val_loss: 4.2022 - val_accuracy: 0.0823\n",
      "Epoch 14/15\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 1.5256 - accuracy: 0.4189 - val_loss: 4.2180 - val_accuracy: 0.0902\n",
      "Epoch 15/15\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 1.3786 - accuracy: 0.5110 - val_loss: 4.2322 - val_accuracy: 0.1041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x176abca7d30>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# 컴파일\n",
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "checkpoint = ModelCheckpoint('seq2seq_model.h5', save_best_only=True)\n",
    "\n",
    "model.fit(\n",
    "    [encoder_input_data_train, decoder_input_data_train],\n",
    "    decoder_output_data_train,\n",
    "    batch_size=32,\n",
    "    epochs=15,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "call() got an unexpected keyword argument 'initial_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Intel\\NLP_Project\\modeling\\4_title_generation.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Intel/NLP_Project/modeling/4_title_generation.ipynb#X32sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m decoder_lstm \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mlayers[\u001b[39m5\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Intel/NLP_Project/modeling/4_title_generation.ipynb#X32sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m decoder_dense \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mlayers[\u001b[39m7\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Intel/NLP_Project/modeling/4_title_generation.ipynb#X32sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m decoder_outputs, state_h, state_c \u001b[39m=\u001b[39m decoder_lstm(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Intel/NLP_Project/modeling/4_title_generation.ipynb#X32sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     model\u001b[39m.\u001b[39;49minput[\u001b[39m1\u001b[39;49m], initial_state\u001b[39m=\u001b[39;49mdecoder_states_inputs\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Intel/NLP_Project/modeling/4_title_generation.ipynb#X32sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Intel/NLP_Project/modeling/4_title_generation.ipynb#X32sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m decoder_states \u001b[39m=\u001b[39m [state_h, state_c]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Intel/NLP_Project/modeling/4_title_generation.ipynb#X32sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m decoder_outputs \u001b[39m=\u001b[39m decoder_dense(decoder_outputs)\n",
      "File \u001b[1;32md:\\Intel\\NLP_Project\\nlp_project\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\Intel\\NLP_Project\\nlp_project\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: call() got an unexpected keyword argument 'initial_state'"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('seq2seq_model.h5')\n",
    "\n",
    "# 훈련된 모델을 사용하여 시퀀스를 디코딩\n",
    "encoder_model = Model(model.input[0], model.layers[6].output)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim * 2,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim * 2,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_lstm = model.layers[5]\n",
    "decoder_dense = model.layers[7]\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    model.input[1], initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [model.input[1]] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = tokenizer_decoder.word_index['<start>']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = tokenizer_decoder.index_word[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if sampled_char == '<end>' or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
