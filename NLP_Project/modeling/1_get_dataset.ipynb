{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple EDA\n",
    "\n",
    "간단하게 데이터를 탐색한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 컬럼이 없는 데이터 프레임들은 임의로 컬럼명을 생성하여 사용한다.\n",
    "df1 = pd.DataFrame(pd.read_csv(\"./crawl_14435163.csv\").values, columns=['title', 'write_date', 'views']) # 데이터프레임 1\n",
    "df2 = pd.DataFrame(pd.read_csv(\"./crawl_20720299.csv\").values, columns=['title', 'write_date', 'views']) # 데이터프레임 2\n",
    "\n",
    "df1 = df1[['title', 'views']] # title과 views열만 사용한다\n",
    "df2 = df2[['title', 'views']]\n",
    "df3 = pd.read_csv(\"./naver_cafe_crawl_fix.csv\")[['title', 'views']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### about df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isna().sum() # 결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info() # data type 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dropna(inplace=True, axis = 0) # 결측치 제거\n",
    "\n",
    "df1['title'] = df1['title'].str.replace(\"[^ㄱ-ㅎ|ㅏ-ㅣ|가-힣|a-zA-Z ]\", \"\", regex=True) # 한글과 알파벳, 공백을 제외하고 제거\n",
    "df1['views'] = df1['views'].str.replace(\"[^0-9]\", \"\", regex=True).astype(int) # label값을 구하기 위해 int타입으로 형전환\n",
    "\n",
    "dup_cnt = df1['title'].loc[df1['title'].duplicated() == True].count() # 중복되는 개수 조회\n",
    "print(f\"{dup_cnt}개의 중복 자료가 존재합니다.\")\n",
    "\n",
    "df1.drop_duplicates(subset=['title'], inplace=True) # 중복 행 제거\n",
    "df1 = df1.reset_index(drop = True) # 인덱스 초기화\n",
    "print(f\"{df1.isna().sum().sum()}개의 결측치가 존재합니다.\") # 결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head() # 한글과 알파엣, 공백이 잘 지워졌는지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### about df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isna().sum() # 결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info() # data type 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1과 동일한 방식으로 진행\n",
    "df2.dropna(inplace=True, axis = 0)\n",
    "\n",
    "df2['title'] = df2['title'].str.replace(\"[^ㄱ-ㅎ|ㅏ-ㅣ|가-힣|a-zA-Z ]\", \"\", regex=True)\n",
    "df2['views'] = df2['views'].str.replace(\"[^0-9]\", \"\", regex=True).astype(int)\n",
    "\n",
    "dup_cnt = df2['title'].loc[df2['title'].duplicated() == True].count()\n",
    "print(f\"{dup_cnt}개의 중복 자료가 존재합니다.\")\n",
    "\n",
    "df2.drop_duplicates(subset=['title'], inplace=True)\n",
    "df2 = df2.reset_index(drop = True)\n",
    "print(f\"{df2.isna().sum().sum()}개의 결측치가 존재합니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### about df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.isna().sum() # 결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.info() # data type 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소수점 자리 아래 확인을 위해서 views 컬럼을 string으로 타입캐스팅\n",
    "df3['views'] = df3['views'].astype('string')\n",
    "df3['views'].loc[df3['views'].str.endswith(\".0\") == True].count() # 모두 소수점 아래 자리는 0이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.dropna(inplace=True, axis = 0) # 결측치 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소수점 아래 자리가 모두 .0 이므로 차후에 정수형으로 변환한다.\n",
    "df3['views'] = df3['views'].astype('string')\n",
    "df3['views'][0].endswith(\".0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  df1, df2에서 진행한 전처리과정 동일하게 진행\n",
    "df3['title'] = df3['title'].str.replace(\"[^ㄱ-ㅎ|ㅏ-ㅣ|가-힣|a-zA-Z ]\", \"\", regex=True)\n",
    "df3['views'] = df3['views'].str.replace(\"[^0-9].\", \"\", regex=True).astype(float).astype(int)\n",
    "\n",
    "dup_cnt = df3['title'].loc[df3['title'].duplicated() == True].count()\n",
    "print(f\"{dup_cnt}개의 중복 자료가 존재합니다.\")\n",
    "\n",
    "df3.drop_duplicates(subset=['title'], inplace=True)\n",
    "df3 = df3.reset_index(drop = True)\n",
    "print(f\"{df3.isna().sum().sum()}개의 결측치가 존재합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3]).reset_index(drop = True) # 전처리 완료한 세 개의 데이터 프레임을 합친다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum() # 결측치 다시확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() # data type 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라벨링 진행\n",
    "각 view_cnt의 평균을 내서 평균보다 높으면 1, 아니라면 0을 부여한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_val = int(df['views'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_list(values, standard):\n",
    "    label_list = []\n",
    "    for value in values:\n",
    "        if value >= standard:\n",
    "            label_list.append(1)\n",
    "        else:\n",
    "            label_list.append(0)\n",
    "            \n",
    "    return label_list\n",
    "\n",
    "df['label'] = get_label_list(df['views'].values, mean_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 병합\n",
    "전처리 후 라벨링 한 두 데이터 프레임을 병합합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라벨값 분포 확인\n",
    "각 라벨별 분포를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시행착오 1 : 라벨값 간 불균형\n",
    "\n",
    "평균\n",
    "\n",
    "|라벨 0|라벨 1|\n",
    "|---|---|\n",
    "|46544건|25657건|\n",
    "\n",
    "평균은 라벨값 간의 큰 격차를 불러오기에, 분위수를 사용한다\n",
    "\n",
    "제 1 사분위수\n",
    "\n",
    "|라벨 0|라벨 1|\n",
    "|---|---|\n",
    "|18040건|54161건|\n",
    "\n",
    "제 2 사분위수\n",
    "\n",
    "|라벨 0|라벨 1|\n",
    "|---|---|\n",
    "|36001건|36200건|\n",
    "\n",
    "그나마 균등하게 분포되는 제 2 사분위수로 채택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quantile1 = df['views'].quantile(.5)\n",
    "print(int(df_quantile1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = get_label_list(df['views'], df_quantile1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()\n",
    "# df.to_csv(\"./origin_df.csv\", sep=\",\", encoding=\"utf8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['views'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"./origin_df.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
