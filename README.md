### Intel AI for future workforce

### 1주차(신경망 이론)

#### 가중치와 편향
- 가중치
흔히들 물건을 살 때 각 조건에 대한 `비중`이 존재한다. 노트북을 산다고 가정하면 아래와 같은 고려 사항들이 존재하게 마련이다.

|조건|비중|
|---|---|
|성능|70%|
|디자인|40%|
|가격|90%|

여기서 비중이 `가중치`에 해당한다고 할 수 있다. 중요하게 생각하는 정도를 의미한다.

- 편향
조건과 비중을 모두 생각하여 특정 `기준`을 만족하면 구매를 행하게 된다. 여기서 기준이 `편향`에 해당한다.

#### 단층 퍼셉트론

#### 초간단 신경망 실습

### 2주차(n by n by n 신경망)
다양한 형상의 신경망을 다뤘다. (1x2x1, 2x3x2, 2x3x1, 3x3x2, ...)

#### 순전파, 역전파

- 순전파 : 입력신호와 가중치, 편향 ➡️ 출력층으로의 흐름을 `순전파`라고 한다. 예측값을 출력하는 과정이라고도 볼 수 있다.

- 역전파 : 신경망을 학습하는 목적은 임의로 설정되는 가중치와 편향의 최적화된 값을 찾는 것이라고 할 수 있다. 최적화된 값들을 찾기 위해서는 지속적으로 가중치와 편향값을 갱신하면서 학습하는데, 이 때 흐르는 방향이 역방향이기에 `역전파`라고 하며, 이 때 `경사하강법`을 이용해서 각 값들을 갱신한다.

- 경사 하강법 : 가중치의 값을 줄일지, 늘릴지를 판단하는 기준은 `위치`이며, 이러한 위치를 알아내는 방법은 `미분`이었다. 해당 가중치에 학습률을 곱한 미분값을 빼거나 더하여, 가중치를 갱신한다.

#### 오미입, 오메가미입
순수 파이썬 코드를 구현할 때, 방대한 양의 미분식으로 인해서 머리가 좀 아팠다. 이러한 미분식을 간단하게 사용할 수 있었던 두 가지 공식이다. `Chain Rule`적용시 간단하게 풀어지는 식(활성화 층을 한 번 거치는 경우)들의 경우 전자의 공식을 사용했고, 여러 개의 식으로 풀어지는(활성화 층을 두 개 이상 거치는) 경우 후자의 공식을 사용했었다.

다양한 형상들의 파이썬 코드 구현은 `[/NN/*.py]`들을 참고할 것.

### 3주차(CNN)
2주차에서 진행했던 완전연결계층(Affine 계층) 앞에, 합성곱 연산층이 추가된 `CNN(Convolutional Neural Network)`을 학습했다.

#### 합성곱 연산
입력되는 이미지를 순회하면서 `Feature Map`을 추출하는 과정이었다. `Filter, Padding, Stride, Pooling`등의 용어가 등장했었다.

|용어|설명|
|---|---|
|Filter|합성곱 연산에서 사용한다. 이미지의 특징을 찾아내기 위한 파라미터이며, 다양한 종류의 필터로 Feature Map을 <br>추출할 수 있다. Kernel이라고 부르기도 한다.|
|Padding|원본 이미지의 형상에 특정 수를 붙여 크기를 늘린다. 합성곱 연산 후 이미지의 크기가 줄어드는 현상을 방지하기 <br>위해서 사용하며, 일반적으로 zero-Padding을 사용한다.|
|Stride|합성곱 연산, 혹은 Pooling 연산 시, 이미지를 순회하는 간격을 의미한다.|
|Pooling|특정 데이터를 강조하거나, 출력 데이터의 크기를 줄이기 위해서 사용한다. Mean Pooling과 Max Pooling이 존재한다.|

#### 미니프로젝트
7/26 ~ 7/28까지 자유 주제로 CNN모델을 학습하는 정말 미니... 한 프로젝트를 진행했다.

- 강아지 표정 분류(다중분류)
> 스토리텔링과 함께 강아지의 표정을 4개의 클래스로 분류(분노, 슬픔, 평온, 행복)

- Project Flow
    + Kaggle에서 데이터 수집
    + 간단한 전처리
    + 모델링(Self Building / Use Pretrained Model(Preference learning))
    + 학습 곡선 가시화 / 예측
    + 해당 프로젝트 파일은 `[/CNN/dog_emotion_classification]`디렉토리에서 확인 가능

얻은 지식들

|Knowledge|explanation|
|---|---|
|전이학습|사전에 훈련된 모델의 전 계층 혹은 Affine계층을 제외한 부분을 가져와 학습하는 형태를 의미한다. <br>해당 프로젝트에서는 Affine계층을 제외하고 가져와, 직접 구현하여 사용했다.|
|미세조정|사전 훈련된 모델의 최상위 일부 몇 개 계층의 가중치를 동결 해제하여 가중치를 재학습 하는 것을 의미. <br>해당 프로젝트에서는 큰 의미가 없어 전부 동결하고 진행|
|ensemble learning|사전 훈련된 모델 다수를 들고와서 학습하는 형태. 각 사전훈련 모델의 output이 다음 모델의 <br>input이 되어 좋은 결과를 낼 수 있다고 한다. 해당 프로젝트에서는 input type관련 오류를 <br>해결하지 못해 사용하지 못했음|

느꼈던 점
- 1. 프로젝트를 행하기 전, 간단한 Project Flow를 구성하여 간단한 피드백을 받고 진행하는 것이 좋을 것 같다.
- 2. 데이터의 중요성

### 4주차(RNN)
- 향후 추가