{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3099 images belonging to 4 classes.\n",
      "Found 3099 images belonging to 4 classes.\n",
      "Found 389 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "num_epoch = 100             # 훈련 횟수\n",
    "learning_rate = 0.001       # 학습률\n",
    "dropout_rate = 0.2          # dropout 비율\n",
    "num_class = 4 \n",
    "batch_size = 8 \n",
    "input_shape = (300, 300, 3) # 150, 224\n",
    "\n",
    "train_dir = \"./dog_dataset_output/train\"\n",
    "test_dir = \"./dog_dataset_output/test\"\n",
    "\n",
    "# 생성기 수정 시도\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function = tf.keras.applications.densenet.preprocess_input, # 0 ~ 1사이 값으로 조정하되, 각 채널은 ImageNet 데이터 세트에 대해 정규화\n",
    "    width_shift_range=0.3,               \n",
    "    zoom_range=0.2,                      \n",
    "    horizontal_flip=True,\n",
    "    fill_mode = 'nearest',\n",
    "    shear_range = 0.2               \n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(      \n",
    "    preprocessing_function = tf.keras.applications.densenet.preprocess_input\n",
    ")\n",
    "\n",
    "train_generator_vgg = train_datagen.flow_from_directory( \n",
    "    train_dir,                 \n",
    "    target_size = input_shape[:2],  \n",
    "    batch_size = batch_size,      \n",
    "    color_mode = 'rgb',           \n",
    "    class_mode='categorical'        \n",
    ")          \n",
    "                         \n",
    "train_generator_densenet = train_datagen.flow_from_directory( \n",
    "    train_dir,                 \n",
    "    target_size = input_shape[:2],  \n",
    "    batch_size = batch_size,      \n",
    "    color_mode = 'rgb',           \n",
    "    class_mode='categorical'        \n",
    ")                                   \n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,                      \n",
    "    target_size=input_shape[:2],    \n",
    "    batch_size=batch_size,          \n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical'        \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG19 -> DenseNet201 -> Affine\n",
    "def get_model(model1, model2):\n",
    "    \n",
    "    params = {'input_shape' : input_shape, \n",
    "              'include_top': False,  # Affine 계층을 포함시키지 않고 직접 구현하여 연결한다.\n",
    "              'weights':'imagenet', # imagenet의 가중치 사용\n",
    "              'pooling':'max',\n",
    "              'classes':4}\n",
    "    \n",
    "    vgg_19 = model1(**params) # **는 dictionary(params)내부의 키:값 쌍을 함수에 keyword 인자(input_shape = input_shape)로 전달합니다.\n",
    "    for pretrained_layer in vgg_19.layers[-3:]: # 사전 학습된 모델의 계층들 \n",
    "        pretrained_layer.trainable = True # 사전 학습된 모델들의 가중치는 동결하되, 최상단의 일부만 동결을 해제하면서 미세조정을 진행\n",
    "        \n",
    "    densenet_201 = model2(**params)\n",
    "    for pretrained_layer in densenet_201.layers[-3:]: \n",
    "        pretrained_layer.trainable = True \n",
    "    \n",
    "    vgg_output = vgg_19.output               # vgg의 output은 densenet의 input이 되고\n",
    "    densenet_output = densenet_201.output    # densenet의 input은 affine계층의 input이 된다.\n",
    "    merged_output = tf.keras.layers.concatenate([vgg_output, densenet_output]) # 두 모델을 결합하고\n",
    "    # 완전연결신경망 구축(functional api method)\n",
    "    x = tf.keras.layers.Flatten()(merged_output) # 결합된 모델을 Affine계층의 입력층으로 전달한다.\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.3)(x)\n",
    "    outputs = tf.keras.layers.Dense(4, activation='softmax')(x)\n",
    "    ensembeled_model = tf.keras.Model(inputs=[vgg_19.input, densenet_201.input], outputs = outputs)\n",
    "\n",
    "    ensembeled_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), loss='categorical_crossentropy', metrics=['acc'])\n",
    "    \n",
    "    return ensembeled_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\OWNER\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\OWNER\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\OWNER\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\OWNER\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\OWNER\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\OWNER\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 216, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model_8\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, None, None, None) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 37\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[39m# 최종 앙상블 모델을 사용하여 학습을 진행합니다.\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     ensembled_model\u001b[39m.\u001b[39mfit([train_generator_vgg, train_generator_densenet], epochs\u001b[39m=\u001b[39mnum_epoch,\n\u001b[0;32m     34\u001b[0m                         callbacks\u001b[39m=\u001b[39m[model_check, reduce_lr, early_stop, logger],\n\u001b[0;32m     35\u001b[0m                         validation_data\u001b[39m=\u001b[39mvalidation_generator)\n\u001b[1;32m---> 37\u001b[0m ensemble_preferation()\n",
      "Cell \u001b[1;32mIn[10], line 15\u001b[0m, in \u001b[0;36mensemble_preferation\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m model_vgg\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate), loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39macc\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     13\u001b[0m model_densenet\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate), loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39macc\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 15\u001b[0m model_vgg\u001b[39m.\u001b[39;49mfit(train_generator_vgg, epochs\u001b[39m=\u001b[39;49mnum_epoch, validation_data\u001b[39m=\u001b[39;49mvalidation_generator,\n\u001b[0;32m     16\u001b[0m               callbacks\u001b[39m=\u001b[39;49m[model_check, reduce_lr, early_stop, logger])\n\u001b[0;32m     18\u001b[0m model_densenet\u001b[39m.\u001b[39mfit(train_generator_densenet, epochs\u001b[39m=\u001b[39mnum_epoch, validation_data\u001b[39m=\u001b[39mvalidation_generator,\n\u001b[0;32m     19\u001b[0m                    callbacks\u001b[39m=\u001b[39m[model_check, reduce_lr, early_stop, logger])\n\u001b[0;32m     21\u001b[0m \u001b[39m# 각 모델의 학습이 끝난 후, 합쳐진 앙상블 모델을 생성합니다.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\OWNER\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file2rh4f3ry.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\OWNER\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\OWNER\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\OWNER\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\OWNER\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\OWNER\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\OWNER\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 216, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model_8\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, None, None, None) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "def ensemble_preferation():\n",
    "    model_check = ModelCheckpoint(filepath=\"./CNN/dog_emotion_classification/model/ensembled/weights/weights.{epoch:02d}-{val_loss:.2f}.hdf5\",\n",
    "                                  monitor=\"val_loss\", save_best_only=True, mode=\"min\")\n",
    "    reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=3, mode=\"min\")\n",
    "    early_stop = EarlyStopping(monitor=\"val_loss\", patience=10, mode=\"min\")\n",
    "    logger = CSVLogger('./CNN/dog_emotion_classification/model/ensembled/VGG19_history.csv')\n",
    "\n",
    "    model_vgg = get_model(tf.keras.applications.VGG19, tf.keras.applications.DenseNet201)\n",
    "    model_densenet = get_model(tf.keras.applications.VGG19, tf.keras.applications.DenseNet201)\n",
    "\n",
    "    # 각 모델을 컴파일합니다.\n",
    "    model_vgg.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), loss='categorical_crossentropy', metrics=['acc'])\n",
    "    model_densenet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "    model_vgg.fit(train_generator_vgg, epochs=num_epoch, validation_data=validation_generator,\n",
    "                  callbacks=[model_check, reduce_lr, early_stop, logger])\n",
    "\n",
    "    model_densenet.fit(train_generator_densenet, epochs=num_epoch, validation_data=validation_generator,\n",
    "                       callbacks=[model_check, reduce_lr, early_stop, logger])\n",
    "\n",
    "    # 각 모델의 학습이 끝난 후, 합쳐진 앙상블 모델을 생성합니다.\n",
    "    vgg_output = model_vgg.layers[-2].output\n",
    "    densenet_output = model_densenet.layers[-2].output\n",
    "    merged_output = tf.keras.layers.concatenate([vgg_output, densenet_output])\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(merged_output)\n",
    "    x = tf.keras.layers.Dropout(rate=0.3)(x)\n",
    "    outputs = tf.keras.layers.Dense(4, activation='softmax')(x)\n",
    "    ensembled_model = tf.keras.Model(inputs=[model_vgg.input, model_densenet.input], outputs=outputs)\n",
    "\n",
    "    ensembled_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "    # 최종 앙상블 모델을 사용하여 학습을 진행합니다.\n",
    "    ensembled_model.fit([train_generator_vgg, train_generator_densenet], epochs=num_epoch,\n",
    "                        callbacks=[model_check, reduce_lr, early_stop, logger],\n",
    "                        validation_data=validation_generator)\n",
    "\n",
    "ensemble_preferation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
