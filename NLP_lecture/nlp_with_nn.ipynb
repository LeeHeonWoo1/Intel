{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신경망으로 챗봇 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전 노트북에서는 코사인 유사성을 가진 챗봇을 만드는 방법을 배웠습니다. 이제는 신경망을 이용해 어떻게 만들 수 있는지 살펴보겠습니다!\n",
    "\n",
    "훈련 데이터를 만들고 신경망을 훈련시킨 다음 훈련된 모델을 사용하여 챗봇을 만들 것입니다.\n",
    "\n",
    "먼저, 필수 라이브러리를 설치할 것입니다. 라이브러리가 설치되지 않은 경우에만 아래 몇 개의 블록을 주석 해제하십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy scipy\n",
    "#!pip install scikit-learn\n",
    "# !pip install pillow\n",
    "# !pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 라이브러리 설치\n",
    "\n",
    "우선 이 신경망 구동 챗봇에 필요한 라이브러리를 설치하겠습니다.\n",
    "Keras는 백엔드에서 텐서플로우(다른 하위 레벨 기계 학습 라이브러리) 를 활용하는 기계 학습 라이브러리입니다. 이렇게 하면 우리의 목적을 위해 심층 신경망을 쉽게 배포할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Intel\\NLP_lecture\\nlp\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense\n",
    " \n",
    "from numpy import argmax\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 입력 훈련 데이터\n",
    "\n",
    "먼저 챗봇에 대한 다음 교육 데이터를 포함하겠습니다.:\n",
    "1. X는 사용자가 입력할 수 있는 다양한 입력을 나타냅니다.\n",
    "2. Y는 입력의 의도를 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ['Hi',\n",
    "     'Hello',\n",
    "     'How are you?',\n",
    "     'I am making',\n",
    "     'making',\n",
    "     'working',\n",
    "     'studying',\n",
    "     'see you later',\n",
    "     'bye',\n",
    "     'goodbye']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = ['greeting',\n",
    "     'greeting',\n",
    "     'greeting',\n",
    "     'busy',\n",
    "     'busy',\n",
    "     'busy',\n",
    "     'busy',\n",
    "     'bye',\n",
    "     'bye',\n",
    "     'bye']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비슷한 의도를 가진 여러 개의 다른 문장들이 있다는 것을 주목하십시오. 여기에서는 3개의 의도(greeting, busy, bye)만 있지만 프로젝트에 원하는 만큼 추가할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이것은 챗봇이 작동하는 방식입니다:\n",
    "1. 입력 문장으로부터, 우리는 훈련된 AI 모델을 사용하여 의도를 확인할 것이다.\n",
    "2. 각 의도에 대해, 우리는 준비 된 응답을 가지고있다.\n",
    "\n",
    "예를 들어, 입력의 의도가 인사말에 대한 것임을 확인하면 챗봇에 '안녕하세요'또는 '어떻게 지내십니까?'와 같은 인사말로 응답하도록 요청할 수 있습니다.\n",
    "\n",
    "우리는 기계 학습을 사용하여 입력 문장을 다른 의도로 분류 할 수있는 모델을 만들 것입니다. \n",
    "다음과 같이 만듭니다:\n",
    "\n",
    "1. 문장과 그 의도에 대한 목록을 포함하고 있는 훈련 데이터(위의 X및  Y)를 작성한다.\n",
    "2. 훈련 데이터를 사용하여 분류기를 훈련한다. \n",
    "3. 입력 문장을 벡터화하고 분류기를 사용하여 의도를 결정한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 텍스트 처리\n",
    "\n",
    "평소와 같이 텍스트 처리부터 시작합니다. 그 과정을 기억하십니까?\n",
    "\n",
    "## 3.1 알파벳과 숫자가 아닌 문자 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_alpha_numeric_characters(sentence):\n",
    "    \"\"\"\n",
    "    문자열 하나를 입력받아 알파벳이 아닌 문자들을 제외하고 새로운 문자열로 구성하여 return 하는 함수\n",
    "    \"\"\"\n",
    "    new_sentence = ''\n",
    "    for alphabet in sentence:\n",
    "        if alphabet.isalpha() or alphabet == ' ':\n",
    "            new_sentence += alphabet\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X):\n",
    "    \"\"\"\n",
    "    배열의 모든 요소에 대해 전처리를 진행한다.\n",
    "    1. 모든 요소를 소문자로 변경.\n",
    "    2. 모든 요소에 remove_non_alpha_numeric_characters 함수를 이용해 알파벳이 아닌 문자열들을 제외.\n",
    "    3. 모든 요소에서 공백을 제거한다.\n",
    "    4. 반복되는 공백을 공백 한 칸으로 변경한다.\n",
    "    \"\"\"\n",
    "    \n",
    "    X = [data_point.lower() for data_point in X]\n",
    "    X = [remove_non_alpha_numeric_characters(sentence) for sentence in X]\n",
    "    X = [data_point.strip() for data_point in X]\n",
    "    X = [re.sub(' +', ' ', data_point) for data_point in X]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess_data(X) # 데이터 전처리\n",
    "\n",
    "vocabulary = set() # BoW 생성을 위한 set 생성\n",
    "for data_point in X:\n",
    "    for word in data_point.split(' '):\n",
    "        vocabulary.add(word)\n",
    "\n",
    "vocabulary = list(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문서 벡터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded = []\n",
    "\n",
    "def encode_sentence(sentence):\n",
    "    sentence = preprocess_data([sentence])[0]\n",
    "    sentence_encoded = [0] * len(vocabulary)\n",
    "    for i in range(len(vocabulary)):\n",
    "        if vocabulary[i] in sentence.split(' '):\n",
    "            sentence_encoded[i] = 1\n",
    "    return sentence_encoded\n",
    "\n",
    "X_encoded = [encode_sentence(sentence) for sentence in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(set(Y))\n",
    "\n",
    "Y_encoded = []\n",
    "for data_point in Y:\n",
    "    data_point_encoded = [0] * len(classes)\n",
    "    for i in range(len(classes)):\n",
    "        if classes[i] == data_point:\n",
    "            data_point_encoded[i] = 1\n",
    "    Y_encoded.append(data_point_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 훈련 데이터 및 테스트 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_encoded\n",
    "y_train = Y_encoded\n",
    "X_test = X_encoded\n",
    "y_test = Y_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 및 테스트 데이터에 사용하는 데이터 출력 및 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 0, 1], [0, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "print (y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "print((X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_train은 무엇을 의미합니까? 위에 표시된 배열을 이해합니까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 모델 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 훈련 데이터를 이용해 신경망을 훈련시키겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Intel\\NLP_lecture\\nlp\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From d:\\Intel\\NLP_lecture\\nlp\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Intel\\NLP_lecture\\nlp\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 270ms/step - loss: 1.1449\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1315\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1160\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1011\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0889\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0806\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0762\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0749\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0754\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0766\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0773\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0769\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0754\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0728\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0695\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0660\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0625\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0594\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0567\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0545\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0525\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0508\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0491\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0473\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0454\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0434\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0413\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0391\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0368\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0346\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0324\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0302\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0281\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0260\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0239\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0219\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0198\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0177\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0156\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0135\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0113\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0092\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0071\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0049\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0028\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0007\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9985\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9964\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9943\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9921\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9900\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9879\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9857\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9836\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9814\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9793\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9771\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9750\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9728\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9706\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9685\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9663\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9641\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9620\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9598\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9576\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9554\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9532\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9510\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9488\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9466\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9444\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9422\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9400\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9378\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9356\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9334\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9311\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9289\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9267\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9244\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9222\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9199\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9177\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9154\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9131\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9109\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9086\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9063\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9040\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9017\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8995\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8972\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8949\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8925\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8902\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8879\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8856\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8833\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x21dc2272d90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='sigmoid',input_dim=len(X_train[0])))\n",
    "model.add(Dense(units=len(y_train[0]), activation='softmax'))\n",
    "\n",
    "model.compile(loss=categorical_crossentropy, optimizer=SGD(lr=0.01, momentum=0.9, nesterov=True))\n",
    "\n",
    "model.fit(np.array(X_train), np.array(y_train), epochs=100, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                960       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1155 (4.51 KB)\n",
      "Trainable params: 1155 (4.51 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예측 목록 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = [argmax(pred) for pred in model.predict(np.array(X_test))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모델을 평가해 봅시다. 모델에 의한 예측과 테스트 데이터를 비교할 것입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 8\n",
      "Total: 10\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] == argmax(y_test[i]):\n",
    "        correct += 1\n",
    "\n",
    "print (\"Correct:\", correct)\n",
    "print (\"Total:\", len(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 챗봇 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 챗봇을 테스트해 보겠습니다! 문장을 입력한 다음 신경망에서 예측되는 클래스를 확인합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a sentence\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "busy\n"
     ]
    }
   ],
   "source": [
    "# while True:\n",
    "print (\"Enter a sentence\")\n",
    "sentence = input()\n",
    "prediction= model.predict(np.array([encode_sentence(sentence)]))\n",
    "print (classes[argmax(prediction)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "챗봇을 멈출 수 없다는 것을 알고 있습니까? 나중에 종료 명령을 추가해야 합니다(이전 노트를 참조하여 수행 방법을 확인하십시오.).\n",
    "\n",
    "일단은 위의 중지 버튼(인터럽트 버튼)을 눌러서 챗봇을 중지하면 됩니다.\n",
    "\n",
    "시도해 보세요. 정지 버튼을 누르고 상자에 뭔가를 입력해 보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 도전과제\n",
    "\n",
    "우리는 성공적으로 대화 의도에 우리의 입력을 매핑하는 신경망을 사용했습니다. \n",
    "여러분의 과제는 대화 의도를 챗봇이 말하는 특정 응답과 연결하는 것입니다. \n",
    "예를 들어, 만약 대화의 목적이 '인사' 라면, 여러분의 챗봇도 인사말을 하도록 하세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 잘했습니다! 신경망으로 간단한 챗봇을 성공적으로 만들었습니다! 챗봇을 어떻게 개선할 수 있을까요?\n",
    "다음과 같은 방법으로 챗봇을 개선할 수 있습니다:\n",
    "- 더 많은 교육 데이터 추가\n",
    "- 더 많은 의도 추가\n",
    "- 특정 주제에 초점을 맞추고 해당 주제에 많은 훈련 데이터로 챗봇 교육"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 출처:\n",
    "https://blog.eduonix.com/internet-of-things/simple-nlp-based-chatbot-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
