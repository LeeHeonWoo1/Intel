{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST - 데이터 증강\n",
    "데이터를 보강하기 위해서 기존의 데이터를 변형해 데이터를 증강할 수 있다. 회전, 반전 등의 방법으로 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data() # 데이터를 로드하고, 데이터 분할\n",
    "\n",
    "num_epoch=1         # 훈련 에포크 회수\n",
    "batch_size=32       # 훈련용 이미지의 묶음\n",
    "learning_rate=0.001 # 학습률, 작을수록 학습 정확도 올라감\n",
    "dropout_rate=0.3    # 30%의 신경망 연결을 의도적으로 끊음. 과적합 방지용 \n",
    "num_class=10        # 분류를 위한 정답의 갯수\n",
    "\n",
    "datagen = ImageDataGenerator(           # 객체 생성\n",
    "    featurewise_center=True,            # input의 평균이 0이 되도록 한다. (표준화)\n",
    "    featurewise_std_normalization=True, # input을 각 특성 내에서 데이터셋의 표준편차로 나눠 정규화 한다.\n",
    "    rotation_range=20,                  # 회전 각도 설정\n",
    "    width_shift_range=0.2,              # 가로넓이 범위\n",
    "    height_shift_range=0.2,             # 세로넓이 범위\n",
    "    horizontal_flip=True)               # 가로 반전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설계\n",
    "model=models.Sequential() # 모델 객체 생성\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1))) # (3, 3)크기의 32개의 각기 다른 필터로 특징 추출(Feature Map 생성)\n",
    "model.add(layers.MaxPooling2D((2,2))) # (2, 2)크기로 Max Pooling\n",
    "model.add(layers.Dropout(dropout_rate)) # Drop out\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu')) # (3, 3)크기의 64개의 각기 다른 필터로 특징 추출(Feature Map 생성)\n",
    "model.add(layers.MaxPooling2D((2,2))) # (2, 2)크기로 Max Pooling\n",
    "model.add(layers.Dropout(dropout_rate)) # Drop out\n",
    "\n",
    "model.add(layers.Flatten()) # 평탄화(입력층)\n",
    "model.add(layers.Dense(64, activation='relu')) # hidden layer. 노드의 개수는 64개\n",
    "model.add(layers.Dense(num_class, activation='softmax')) # 출력층. softmax로 활성화 하여 0~9 숫자의 확률로 출력\n",
    " \n",
    "# 모델 컴파일\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2486 - acc: 0.9225\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2285 - acc: 0.9283\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2152 - acc: 0.9317\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2047 - acc: 0.9356\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1969 - acc: 0.9386\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1933 - acc: 0.9395\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1893 - acc: 0.9407\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1858 - acc: 0.9420\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.1831 - acc: 0.9433\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.1753 - acc: 0.9448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25133dab0d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = train_images.reshape(-1, 28, 28, 1)\n",
    "datagen.fit(train_images)\n",
    "\n",
    "# 각 이미지에 대해서 실시간으로 데이터 증강을 사용해 배치에 대해서 모델을 학습\n",
    "model.fit(datagen.flow(train_images, train_labels, batch_size=32),\n",
    "                steps_per_epoch=len(train_images) / 32, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
