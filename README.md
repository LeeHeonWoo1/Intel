### Intel AI for future workforce

### 1주차(신경망 이론)

#### 가중치와 편향
- 가중치
흔히들 물건을 살 때 각 조건에 대한 `비중`이 존재한다. 노트북을 산다고 가정하면 아래와 같은 고려 사항들이 존재하게 마련이다.

|조건|비중|
|---|---|
|성능|70%|
|디자인|40%|
|가격|90%|

여기서 비중이 `가중치`에 해당한다고 할 수 있다. 중요하게 생각하는 정도를 의미한다.

- 편향
조건과 비중을 모두 생각하여 특정 `기준`을 만족하면 구매를 행하게 된다. 여기서 기준이 `편향`에 해당한다.

#### 단층 퍼셉트론

#### 초간단 신경망 실습

<hr>

### 2주차(n by n by n 신경망)
다양한 형상의 신경망을 다뤘다. (1x2x1, 2x3x2, 2x3x1, 3x3x2, ...)

#### 순전파, 역전파

- 순전파 : 입력신호와 가중치, 편향 ➡️ 출력층으로의 흐름을 `순전파`라고 한다. 예측값을 출력하는 과정이라고도 볼 수 있다.

- 역전파 : 신경망을 학습하는 목적은 임의로 설정되는 가중치와 편향의 최적화된 값을 찾는 것이라고 할 수 있다. 최적화된 값들을 찾기 위해서는 지속적으로 가중치와 편향값을 갱신하면서 학습하는데, 이 때 흐르는 방향이 역방향이기에 `역전파`라고 하며, 이 때 `경사하강법`을 이용해서 각 값들을 갱신한다.

- 경사 하강법 : 가중치의 값을 줄일지, 늘릴지를 판단하는 기준은 `위치`이며, 이러한 위치를 알아내는 방법은 `미분`이었다. 해당 가중치에 학습률을 곱한 미분값을 빼거나 더하여, 가중치를 갱신한다.

#### 오미입, 오메가미입
순수 파이썬 코드를 구현할 때, 방대한 양의 미분식으로 인해서 머리가 좀 아팠다. 이러한 미분식을 간단하게 사용할 수 있었던 두 가지 공식이다. `Chain Rule`적용시 간단하게 풀어지는 식(활성화 층을 한 번 거치는 경우)들의 경우 전자의 공식을 사용했고, 여러 개의 식으로 풀어지는(활성화 층을 두 개 이상 거치는) 경우 후자의 공식을 사용했었다.

다양한 형상들의 파이썬 코드 구현은 `[/NN/*.py]`들을 참고할 것.

<hr>

### 3주차(CNN)
2주차에서 진행했던 완전연결계층(Affine 계층) 앞에, 합성곱 연산층이 추가된 `CNN(Convolutional Neural Network)`을 학습했다.

#### 합성곱 연산
입력되는 이미지를 순회하면서 `Feature Map`을 추출하는 과정이었다. `Filter, Padding, Stride, Pooling`등의 용어가 등장했었다.

|용어|설명|
|---|---|
|Filter|합성곱 연산에서 사용한다. 이미지의 특징을 찾아내기 위한 파라미터이며, 다양한 종류의 필터로 Feature Map을 추출한다. Kernel이라고 부르기도 한다.|
|Padding|원본 이미지의 형상에 특정 수를 붙여 크기를 늘린다. 합성곱 연산 후 이미지의 크기가 줄어드는 현상을 방지하기 위해서 사용하며, 일반적으로 zero-Padding을 사용한다.|
|Stride|합성곱 연산, 혹은 Pooling 연산 시, 이미지를 순회하는 간격을 의미한다.|
|Pooling|특정 데이터를 강조하거나, 출력 데이터의 크기를 줄이기 위해서 사용한다. Mean Pooling과 Max Pooling이 존재한다.|

#### 미니프로젝트
7/26 ~ 7/28까지 자유 주제로 CNN모델을 학습하는 정말 미니... 한 프로젝트를 진행했다.

- 강아지 표정 분류(다중분류)
> 스토리텔링과 함께 강아지의 표정을 4개의 클래스로 분류(분노, 슬픔, 평온, 행복)

단순히 CNN만 사용하기에는 아쉬울 듯 하여, 전이학습과 미세조정, 앙상블 학습을 도전했다.

- Project Flow
    + Kaggle에서 데이터 수집
    + 간단한 전처리
    + 모델링(Self Building vs Use Pretrained Model(Preference learning))
    + 학습 곡선 가시화 / 예측
    + 해당 프로젝트 파일은 `[/CNN/dog_emotion_classification]`디렉토리에서 확인 가능

얻은 지식들

|Knowledge|explanation|
|---|---|
|전이학습|사전에 훈련된 모델의 전 계층 혹은 Affine계층을 제외한 부분을 가져와 학습하는 형태를 의미한다. 해당 프로젝트에서는 Affine계층을 제외하고 가져와, 직접 구현하여 사용했다.|
|미세조정|사전 훈련된 모델의 최상위 일부 몇 개 계층의 가중치를 동결 해제하여 가중치를 재학습 하는 것을 의미. 해당 프로젝트에서는 큰 의미가 없어 전부 동결하고 진행|
|ensemble learning|사전 훈련된 모델 다수를 들고와서 학습하는 형태. 각 사전훈련 모델의 output이 다음 모델의 input이 되어 좋은 결과를 낼 수 있다고 한다. 해당 프로젝트에서는 input type관련 오류를 해결하지 못해 사용하지 못했음|

느꼈던 점
- 1. 프로젝트를 행하기 전, 간단한 Project Flow를 구성하여 간단한 피드백을 받고 진행하는 것이 좋을 것 같다.
- 2. 데이터의 중요성

<hr>

### 4주차(RNN)
- RNN(Recurrent Neural Network) : 일반적인 피드 포워드 방식(입력층 ➡️ 출력층)의 구조와는 다르게, 이전 시점의 은닉층에서 활성화 된 결과를 출력층에도 보내되, 다음 시점의 은닉층에서 불러 사용하는 `재귀적인 성질을 띠는 구조`를 가진 신경망이다.

- RNN의 문제점 : 시퀀스의 길이가 짧은 문제에 대해서만 효용적이다. 먼 이전 시점의 입력값이 뒷 시점으로 이동할수록 기억이 옅어져, 제대로 된 예측이 진행되지 않는 `장기 의존성 문제`가 발생한다. 이러한 단점을 고려하여 LSTM(Long-Short-Term-Memory), GRU(Gate-Recurrent-Unit)등의 모델이 고안되었다.

### LSTM(Long Short Term Memory)
RNN의 장기 의존성 문제를 해결하기 위해 고안된 LSTM모델은 3가지의 게이트가 도입된 방식을 사용한다. 입력 값 형상의 경우 (데이터의 개수, 특성의 개수, 스텝 수) 로 구성된다.

- Forget gate(망각 게이트) : 이전 시점의 출력값(현재 시점의 입력값)을 사용하는 비율을 결정하는 게이트이다. 시그모이드 함수로 활성화 되며, 0에 가까울수록 망각, 1에 가까울수록 온전하게 가져감을 의미한다.
- Input gate(입력 게이트) : 입력값을 sigmoid or tanh 함수로 활성화 하여 입력하는 게이트이다. 이 과정에서 새로운 특징이 추출될 수 있다.
- Output gate(출력 게이트) : 앞선 두 게이트를 거쳐 출력층과 다음 메모리 셀에 출력한다. 마찬가지로 sigmoid로 활성화 되어 출력값을 조절한다고 볼 수 있다.

> 내멋대로 진행해본 제주 태양광 발전량 예측 : https://github.com/LeeHeonWoo1/Intel/blob/master/RNN/solar_power_prediction.ipynb

### YOLO
You Only Look Once의 약자로 객체 탐지 시스템을 얘기한다. 사용한 버전은 YoloV5이며, 내부 구조는 Backbone, neck, head로 구성된다.

- Backbone : 입력되는 이미지들로부터 `CSP-Darknet`을 이용하여 특성맵을 추출한다. CSP-Darknet의 경우 연산량을 크게 줄여주고, 정확도 향상과 inference time을 줄여준다.

- Head : 추출된 특성맵을 기반으로 물체의 위치를 찾는다. 

### Train with Custom Data
이미 시중에 나와있는 데이터가 아닌, 내가 원하는 물체들만 탐지할 수 있도록 커스텀 데이터를 기반으로 학습을 진행했다.

> 의류 종류 탐지하기 : https://github.com/LeeHeonWoo1/Intel/blob/master/TrainCustomData.ipynb

**training flow**
- 하이버에서 이미지 수집
- Roboflow에서 Annotating(Image Augmentation 적용, 총 900여 장의 이미지)
- 학습된 가중치(yolov5n)를 기반으로 학습(yolov5m)
- 임의의 데이터에 대한 탐지

<hr>

### 5주차
Yolov5 기반 Custom data training 진행

<hr>

### 6주차
GAN간단 이론

<hr>

### 7주차(주차벌 미니 프로젝트 시작)
첫 번째 미니프로젝트 : 종이 헬리콥터 회귀분석

코드는 `projects/paper Helicopter` 에서 확인할 수 있다.

<hr>

### 8주차
두 번째, 세 번째 미니 프로젝트 : CNN활용 프로젝트

코드는 `projects/CompletionSignal` 과 `projects/NavigationPt` 에서 확인할 수 있다.

<hr>

### 9주차
YoloV5기반 Custom data로 진행하는 미니 프로젝트를 진행한다.
